{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "691f9678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:00:34.534973Z",
     "iopub.status.busy": "2023-04-21T20:00:34.534488Z",
     "iopub.status.idle": "2023-04-21T20:00:34.542484Z",
     "shell.execute_reply": "2023-04-21T20:00:34.541034Z"
    },
    "papermill": {
     "duration": 0.019148,
     "end_time": "2023-04-21T20:00:34.545489",
     "exception": false,
     "start_time": "2023-04-21T20:00:34.526341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ec10fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:00:34.560404Z",
     "iopub.status.busy": "2023-04-21T20:00:34.559980Z",
     "iopub.status.idle": "2023-04-21T20:00:34.632863Z",
     "shell.execute_reply": "2023-04-21T20:00:34.631391Z"
    },
    "papermill": {
     "duration": 0.084176,
     "end_time": "2023-04-21T20:00:34.636247",
     "exception": false,
     "start_time": "2023-04-21T20:00:34.552071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab3ef656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:00:34.915562Z",
     "iopub.status.busy": "2023-04-21T20:00:34.915137Z",
     "iopub.status.idle": "2023-04-21T20:00:34.926287Z",
     "shell.execute_reply": "2023-04-21T20:00:34.924841Z"
    },
    "papermill": {
     "duration": 0.031108,
     "end_time": "2023-04-21T20:00:34.928806",
     "exception": false,
     "start_time": "2023-04-21T20:00:34.897698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['TweetText'] = train_df['TweetText'].apply(lambda x: x.replace('RT', '').replace(\"'RT\", ''))\n",
    "test_df['TweetText'] = test_df['TweetText'].apply(lambda x: x.replace('RT', '').replace(\"'RT\", ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefc9b1",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8204b8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:00:34.999389Z",
     "iopub.status.busy": "2023-04-21T20:00:34.997980Z",
     "iopub.status.idle": "2023-04-21T20:00:48.281157Z",
     "shell.execute_reply": "2023-04-21T20:00:48.279400Z"
    },
    "papermill": {
     "duration": 13.297763,
     "end_time": "2023-04-21T20:00:48.284730",
     "exception": false,
     "start_time": "2023-04-21T20:00:34.986967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2054f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:00:49.072723Z",
     "iopub.status.busy": "2023-04-21T20:00:49.072304Z",
     "iopub.status.idle": "2023-04-21T20:01:02.013920Z",
     "shell.execute_reply": "2023-04-21T20:01:02.011989Z"
    },
    "papermill": {
     "duration": 12.953271,
     "end_time": "2023-04-21T20:01:02.016996",
     "exception": false,
     "start_time": "2023-04-21T20:00:49.063725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "     ------------------------------------ 289.9/289.9 kB 198.9 kB/s eta 0:00:00\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.0.0-cp310-cp310-win_amd64.whl (39 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ca257ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:00:48.302966Z",
     "iopub.status.busy": "2023-04-21T20:00:48.301936Z",
     "iopub.status.idle": "2023-04-21T20:00:49.053016Z",
     "shell.execute_reply": "2023-04-21T20:00:49.051430Z"
    },
    "papermill": {
     "duration": 0.763697,
     "end_time": "2023-04-21T20:00:49.056447",
     "exception": false,
     "start_time": "2023-04-21T20:00:48.292750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "train_df['Cleaned_Tweet'] = train_df['TweetText'].apply(lambda x: p.clean(x))\n",
    "test_df['Cleaned_Tweet'] = test_df['TweetText'].apply(lambda x: p.clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23f3660a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:01:06.053321Z",
     "iopub.status.busy": "2023-04-21T20:01:06.052845Z",
     "iopub.status.idle": "2023-04-21T20:01:09.379477Z",
     "shell.execute_reply": "2023-04-21T20:01:09.378382Z"
    },
    "papermill": {
     "duration": 3.345685,
     "end_time": "2023-04-21T20:01:09.382365",
     "exception": false,
     "start_time": "2023-04-21T20:01:06.036680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\younes\n",
      "[nltk_data]     G\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\younes\n",
      "[nltk_data]     G\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import contractions\n",
    "\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', (word))\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "w_tokenizer = TweetTokenizer()\n",
    "\n",
    "def lemmatize_text(words):\n",
    "    return [lemmatizer.lemmatize(w) for w in words]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if not w in stop_words]\n",
    "    return words\n",
    "\n",
    "def preprocess(text):\n",
    "    text = remove_digits(text)\n",
    "    text = expand_contractions(text)\n",
    "    words = w_tokenizer.tokenize(text)\n",
    "    words = remove_punctuation(words)\n",
    "    words = lemmatize_text(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "train_df['Cleaned_Tweet'] = train_df['Cleaned_Tweet'].apply(preprocess)\n",
    "test_df['Cleaned_Tweet'] = test_df['Cleaned_Tweet'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d84d48c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T20:01:09.433433Z",
     "iopub.status.busy": "2023-04-21T20:01:09.433030Z",
     "iopub.status.idle": "2023-04-21T20:01:09.448571Z",
     "shell.execute_reply": "2023-04-21T20:01:09.447035Z"
    },
    "papermill": {
     "duration": 0.028481,
     "end_time": "2023-04-21T20:01:09.451524",
     "exception": false,
     "start_time": "2023-04-21T20:01:09.423043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\younes G\\AppData\\Local\\Temp\\ipykernel_34136\\1087680211.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test_df = test_df[train_df['Cleaned_Tweet'].str.strip().astype(bool)]\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['Cleaned_Tweet'].str.strip().astype(bool)]\n",
    "test_df = test_df[train_df['Cleaned_Tweet'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42345fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Label</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304271250237304833</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
       "      <td>[value, measured, dollar, term, deepest, ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304834304222064640</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'@rraina1481 I fear so'</td>\n",
       "      <td>[fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303568995880144898</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
       "      <td>[watch, video, highlight, final, australia, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304366580664528896</td>\n",
       "      <td>Sports</td>\n",
       "      <td>' @chelscanlan: At Nitro Circus at #AlbertPark...</td>\n",
       "      <td>[nitro, circus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296770931098009601</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
       "      <td>[always, good, thing, thanks, feedback]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId     Label  \\\n",
       "0  304271250237304833  Politics   \n",
       "1  304834304222064640  Politics   \n",
       "2  303568995880144898    Sports   \n",
       "3  304366580664528896    Sports   \n",
       "4  296770931098009601    Sports   \n",
       "\n",
       "                                           TweetText  \\\n",
       "0  '#SecKerry: The value of the @StateDept and @U...   \n",
       "1                            '@rraina1481 I fear so'   \n",
       "2  'Watch video highlights of the #wwc13 final be...   \n",
       "3  ' @chelscanlan: At Nitro Circus at #AlbertPark...   \n",
       "4  '@cricketfox Always a good thing. Thanks for t...   \n",
       "\n",
       "                                       Cleaned_Tweet  \n",
       "0  [value, measured, dollar, term, deepest, ameri...  \n",
       "1                                             [fear]  \n",
       "2  [watch, video, highlight, final, australia, we...  \n",
       "3                                    [nitro, circus]  \n",
       "4            [always, good, thing, thanks, feedback]  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a7d81",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ab1beb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counts_in_tweet(data):\n",
    "    count = [0 for i in range(data.shape[0]) ]\n",
    "    for i in range(data.shape[0]) :\n",
    "        count[i]=len(data['Cleaned_Tweet'][i])\n",
    "    data['Word_Count'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b7128e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_in_tweet(train_df)\n",
    "word_counts_in_tweet(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcd5b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(data):\n",
    "    freqs = {}\n",
    "    for i in range(data.shape[0]) :\n",
    "        label = data['Label'][i]\n",
    "        for word in  data['Cleaned_Tweet'][i]:\n",
    "            pair = ((word,label))\n",
    "            if pair in freqs :\n",
    "                freqs[pair] += 1\n",
    "            else :\n",
    "                freqs[pair] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd889d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = word_count(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5abb6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tweet(data,freqs) :\n",
    "    politics_weights = [0 for i in range(data.shape[0])]\n",
    "    sports_weights = [0 for i in range(data.shape[0])]\n",
    "    for i in range(data.shape[0]) :\n",
    "        for word in  data['Cleaned_Tweet'][i]:\n",
    "            if (word,'Politics') in freqs :\n",
    "                 politics_weights[i] += freqs.get((word,'Politics'))\n",
    "            if (word,'Sports') in freqs :\n",
    "                sports_weights[i] += freqs.get((word,'Sports'))\n",
    "    data['politic_Weight'] = politics_weights\n",
    "    data['sport_Weight'] = sports_weights \n",
    "    data.drop(columns=['Cleaned_Tweet'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30e6a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_tweet(train_df,freqs)\n",
    "vectorize_tweet(test_df,freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33e35f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Label</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>politic_Weight</th>\n",
       "      <th>sport_Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304271250237304833</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'#SecKerry: The value of the @StateDept and @U...</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304834304222064640</td>\n",
       "      <td>Politics</td>\n",
       "      <td>'@rraina1481 I fear so'</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303568995880144898</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'Watch video highlights of the #wwc13 final be...</td>\n",
       "      <td>7</td>\n",
       "      <td>269</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304366580664528896</td>\n",
       "      <td>Sports</td>\n",
       "      <td>' @chelscanlan: At Nitro Circus at #AlbertPark...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296770931098009601</td>\n",
       "      <td>Sports</td>\n",
       "      <td>'@cricketfox Always a good thing. Thanks for t...</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetId     Label  \\\n",
       "0  304271250237304833  Politics   \n",
       "1  304834304222064640  Politics   \n",
       "2  303568995880144898    Sports   \n",
       "3  304366580664528896    Sports   \n",
       "4  296770931098009601    Sports   \n",
       "\n",
       "                                           TweetText  Word_Count  \\\n",
       "0  '#SecKerry: The value of the @StateDept and @U...           7   \n",
       "1                            '@rraina1481 I fear so'           1   \n",
       "2  'Watch video highlights of the #wwc13 final be...           7   \n",
       "3  ' @chelscanlan: At Nitro Circus at #AlbertPark...           2   \n",
       "4  '@cricketfox Always a good thing. Thanks for t...           5   \n",
       "\n",
       "   politic_Weight  sport_Weight  \n",
       "0             113             4  \n",
       "1               6             2  \n",
       "2             269           430  \n",
       "3               0             4  \n",
       "4              99           254  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1d6a9",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "721d5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f477c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Label'] = train_df['Label'].map({'Sports':0,'Politics':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "029988c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_df['Label']\n",
    "X = train_df.drop(columns=['TweetId','Label','TweetText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "440dae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb4a4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [\n",
    "    RandomForestClassifier(random_state=52),\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SVC(probability=True)\n",
    "]\n",
    "\n",
    "df = {\"Model\": [], \"Roc_Auc Score\": [], \"Score\":[],\"Cross validation score\":[]}\n",
    "for algo in algos:\n",
    "    model = algo.fit(X_train, y_train)\n",
    "    y_pred = algo.predict_proba(X_test)[:, 1]\n",
    "    df[\"Model\"].append(str(algo)[:str(algo).find('(')])\n",
    "    df[\"Roc_Auc Score\"].append(roc_auc_score(y_test, y_pred))\n",
    "    df['Score'].append(algo.score(X_test, y_test))\n",
    "    df['Cross validation score'].append(cross_val_score(algo, X, Y, cv=5).mean())\n",
    "\n",
    "models = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7aef2de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Roc_Auc Score</th>\n",
       "      <th>Score</th>\n",
       "      <th>Cross validation score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.951851</td>\n",
       "      <td>0.881001</td>\n",
       "      <td>0.884444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.899580</td>\n",
       "      <td>0.806946</td>\n",
       "      <td>0.810268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.855684</td>\n",
       "      <td>0.849847</td>\n",
       "      <td>0.848429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.935492</td>\n",
       "      <td>0.875894</td>\n",
       "      <td>0.878008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.951552</td>\n",
       "      <td>0.891216</td>\n",
       "      <td>0.885057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>0.881512</td>\n",
       "      <td>0.879234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Roc_Auc Score     Score  Cross validation score\n",
       "0  RandomForestClassifier       0.951851  0.881001                0.884444\n",
       "1              GaussianNB       0.899580  0.806946                0.810268\n",
       "2  DecisionTreeClassifier       0.855684  0.849847                0.848429\n",
       "3    KNeighborsClassifier       0.935492  0.875894                0.878008\n",
       "4      LogisticRegression       0.951552  0.891216                0.885057\n",
       "5                     SVC       0.950989  0.881512                0.879234"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c3e82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "evaluation = {\"Model\":[],\"Accuracy\":[],\"Precision\":[]}\n",
    "for algo in algos:\n",
    "    algo.fit(X_train, y_train)\n",
    "    y = algo.predict_proba(X_test)\n",
    "    y_pred = []\n",
    "    for l in y:\n",
    "        if l[0] > l[1]:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    tn, fp, fn, tp =confusion_matrix(y_test,y_pred).ravel()\n",
    "    accuracy = (tp+tn)/(tn+tp+fn+fp)\n",
    "    precision = tp / (tp+fp)\n",
    "    evaluation[\"Model\"].append(str(algo)[:str(algo).find('(')])\n",
    "    evaluation[\"Accuracy\"].append(accuracy)\n",
    "    evaluation[\"Precision\"].append(precision)\n",
    "algos_evaluation = pd.DataFrame(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0fb5f755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.880490</td>\n",
       "      <td>0.903122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.806946</td>\n",
       "      <td>0.912688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.850358</td>\n",
       "      <td>0.854938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.875894</td>\n",
       "      <td>0.889474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.891216</td>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.885087</td>\n",
       "      <td>0.908405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision\n",
       "0  RandomForestClassifier  0.880490   0.903122\n",
       "1              GaussianNB  0.806946   0.912688\n",
       "2  DecisionTreeClassifier  0.850358   0.854938\n",
       "3    KNeighborsClassifier  0.875894   0.889474\n",
       "4      LogisticRegression  0.891216   0.926829\n",
       "5                     SVC  0.885087   0.908405"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algos_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7876590",
   "metadata": {},
   "source": [
    "# Hyper-parametre Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "494095dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "472e74a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C':[0.011,0.012,0.013,0.014,0.015,0.016,0.017]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35860cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best hyperparameters:  {'C': 0.017}\n",
      "Best accuracy score:  0.8806608171296684\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# Instantiate GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5, verbose=2,n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV object to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Print best hyperparameters and corresponding accuracy score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best accuracy score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a714dc6",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6d88df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(C = 0.017)\n",
    "classifier.fit(X,Y)\n",
    "y_pred = classifier.predict(test_df.drop(columns=['TweetId','TweetText'],inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "997a47d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b77bb865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>306486520121012224</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286353402605228032</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289531046037438464</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>306451661403062273</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>297941800658812928</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>282023761044189184</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>303879735006601216</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>297956846046703616</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>304265049537658880</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>306430391928115200</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TweetId     Label\n",
       "0     306486520121012224    Sports\n",
       "1     286353402605228032    Sports\n",
       "2     289531046037438464  Politics\n",
       "3     306451661403062273  Politics\n",
       "4     297941800658812928    Sports\n",
       "...                  ...       ...\n",
       "2605  282023761044189184    Sports\n",
       "2606  303879735006601216    Sports\n",
       "2607  297956846046703616    Sports\n",
       "2608  304265049537658880    Sports\n",
       "2609  306430391928115200  Politics\n",
       "\n",
       "[2610 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['TweetId']=test_df['TweetId']\n",
    "label = ['Sports' if  y_pred[i]==0 else 'Politics' for i in range(len(y_pred))]\n",
    "submit['Label'] = label\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de329977",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba52235",
   "metadata": {},
   "source": [
    "My approach to improve the current solution is cleaning the data in a efficient way and minimizing the number of features using PCA also we can use RNN (lstm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d415fc",
   "metadata": {},
   "source": [
    "Released By GUENDOUL Younes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e5621",
   "metadata": {},
   "source": [
    "team name in the competition : PGX-DS-T16161"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3672.053013,
   "end_time": "2023-04-21T21:01:34.343691",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-21T20:00:22.290678",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
